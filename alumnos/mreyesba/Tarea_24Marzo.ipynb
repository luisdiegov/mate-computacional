{
 "metadata": {
  "name": "",
  "signature": "sha256:502465f17e51f483cd55b42821cc6608e165224fb41ff23529242615aa969fc6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from IPython.html.widgets import interact, fixed\n",
      "from IPython.html import widgets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "class RegresionLineal:\n",
      "    def __init__(self, alpha=0.3, max_iters=100, tols=0.001):\n",
      "        \"\"\"\n",
      "        Par\u00e1metros.\n",
      "        ---------------\n",
      "        alpha = Learning rate\n",
      "        max_iters = N\u00famero m\u00e1ximo de iteraciones\n",
      "        tols = definici\u00f3n de convergencia\n",
      "        \"\"\"\n",
      "        self.alpha = alpha\n",
      "        self.max_iters = max_iters\n",
      "        self.tols = tols\n",
      "        self.breaking_iteration = None\n",
      "        self.historia = {'costo':[], 'beta':[]}  # Con fines de graficaci\u00f3n\n",
      "        \n",
      "    def gradientDescent(self, x, y):\n",
      "        \"\"\"\n",
      "        Par\u00e1metros:\n",
      "        ---------------\n",
      "        x = vector de entrenamiento de features\n",
      "        y = vector de entrenamiento de variable a predecir (target)\n",
      "        \"\"\"    \n",
      "        \n",
      "        # ajustamos el vector de features\n",
      "        unos = np.ones((x.shape[0], 1))\n",
      "        Xt = X.reshape(x.shape[0], 1)\n",
      "        Xt = np.concatenate((unos, Xt), axis=1)\n",
      "        \n",
      "        i = 0\n",
      "        prep_J = 0\n",
      "        m, n = Xt.shape\n",
      "        self.beta = np.zeros(n) \n",
      "        \n",
      "        while i < self.max_iters:     \n",
      "            # Actualizamos beta\n",
      "            self.beta = self.beta - self.alpha * self.gradiente(Xt, y)\n",
      "            \n",
      "            J = self.costo(Xt, y)\n",
      "            \n",
      "            if abs(J - prep_J) <= self.tols:\n",
      "                print 'La funci\u00f3n convergi\u00f3 con beta: %s en la iteraci\u00f3n %i' % ( str(self.beta), i )\n",
      "                self.breaking_iteration = i\n",
      "                break\n",
      "            else:\n",
      "                prep_J = J\n",
      "            \n",
      "            self.historia['costo'].append(J)\n",
      "            self.historia['beta'].append(self.beta)                \n",
      "            i += 1\n",
      "    \n",
      "    def hipotesis(self, x):\n",
      "        return np.dot(x, self.beta)\n",
      "    \n",
      "    def costo(self, x, y):\n",
      "        m = x.shape[0]\n",
      "        error = self.hipotesis(x) - y\n",
      "        return np.dot(error.T, error) / (2 * m) \n",
      "    \n",
      "    def gradiente(self, x, y):\n",
      "        m = x.shape[0]\n",
      "        error = self.hipotesis(x) - y        \n",
      "        return np.dot(x.T, error) / m   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plotModelo(x,y,rl,iteracion):\n",
      "    modelo = lambda x,b,m: b + m*x # funci\u00f3n para graficar el modelo\n",
      "    \n",
      "    _beta = rl.historia['beta'][iteracion]\n",
      "\n",
      "    fig, ax = plt.subplots(1,2, figsize=(10,6))\n",
      "    ax[0].scatter(x,y, label=\"datos\")\n",
      "    ax[0].plot(x, modelo(x, _beta[0], _beta[1]), label=\"int: %1.2f, pen: %1.2f\" % (_beta[0], _beta[1]))\n",
      "    ax[0].set_xlabel('Edad (yr)')\n",
      "    ax[0].set_ylabel('Altura (m)')\n",
      "    ax[0].legend(loc=\"best\")\n",
      "    #ax[0].set_xlim(0, max(x))\n",
      "    #ax[0].set_ylim(0, max(y))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_1 = np.loadtxt('../../lecture_5/data/chirps.txt', usecols = [0])\n",
      "Y_1 = np.loadtxt('../../lecture_5/data/chirps.txt', usecols = [1])\n",
      "plt.scatter(X_1,Y_1, label=\"data\")\n",
      "plt.xlabel('Chirps')\n",
      "plt.ylabel('Seconds')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = RegresionLineal(alpha=0.03, max_iters=10000, tols=0.0000001)\n",
      "r.gradientDescent(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plotModelo(X_1,Y_1,r,3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x1=np.array([10.0,8.0,13.0,9.0,11.0,14.0,6.0,4.0,12.0,7.0,5.0])\n",
      "y1=np.array([8.04,6.95,7.58,8.81,8.33,9.96,7.24,4.26,10.84,4.82,5.68])\n",
      "y2=np.array([9.14,8.14,8.74,8.77,9.26,8.10,6.13,3.10,9.13,7.26,4.74])\n",
      "y3=np.array([7.46,6.77,12.74,7.11,7.81,8.84,6.08,5.39,8.15,6.42,5.73])\n",
      "x4=np.array([8.0,8.0,8.0,8.0,8.0,8.0,8.0,19.0,8.0,8.0,8.0])\n",
      "y4=np.array([6.58,5.76,7.71,8.84,8.47,7.04,5.25,12.50,5.56,7.91,6.89])\n",
      "fig, ax = plt.subplots(1,4, figsize=(10,6))\n",
      "ax[0].scatter(x1,y1, label=\"data\")\n",
      "ax[1].scatter(x1,y2, label=\"data\")\n",
      "ax[2].scatter(x1,y3, label=\"data\")\n",
      "ax[3].scatter(x4,y4, label=\"data\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = RegresionLineal(alpha=0.03, max_iters=10000, tols=0.0000001)\n",
      "r.gradientDescent(x1, y1)\n",
      "r = RegresionLineal(alpha=0.03, max_iters=10000, tols=0.0000001)\n",
      "r.gradientDescent(x1, y2)\n",
      "r = RegresionLineal(alpha=0.03, max_iters=10000, tols=0.0000001)\n",
      "r.gradientDescent(x1, y3)\n",
      "r = RegresionLineal(alpha=0.03, max_iters=10000, tols=0.0000001)\n",
      "r.gradientDescent(x4, y4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.loadtxt('../../lecture_5/data/radioactive_decay.txt', usecols = [0])\n",
      "Y = np.loadtxt('../../lecture_5/data/radioactive_decay.txt', usecols = [1])\n",
      "plt.scatter(X,Y, label=\"data\")\n",
      "plt.xlabel('time')\n",
      "plt.ylabel('N_(remaining)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}